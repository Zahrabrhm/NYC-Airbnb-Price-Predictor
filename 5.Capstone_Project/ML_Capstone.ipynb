{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wik78BA5Fo2r"
      },
      "source": [
        "**Finding the right per night listing price for an airbnb listing in the new york city**\n",
        "\n",
        "in order to do data cleaning we need to load the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "srSddtIQDHXS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import r2_score, mean_absolute_error,explained_variance_score,max_error\n",
        "df=pd.read_csv('AB_NYC_2019.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9gTyOoMF1I5"
      },
      "source": [
        "after loading the dataset we will start to do datacleaning in several steps:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7lEuV3FGGPc"
      },
      "source": [
        "1.dentifying and dealing with missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4Z1jCagGHGT",
        "outputId": "8d28ca2f-2128-4634-ff45-0106b75fd369"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "missing values:  id                                    0\n",
            "name                                 16\n",
            "host_id                               0\n",
            "host_name                            21\n",
            "neighbourhood_group                   0\n",
            "neighbourhood                         0\n",
            "latitude                              0\n",
            "longitude                             0\n",
            "room_type                             0\n",
            "price                                 0\n",
            "minimum_nights                        0\n",
            "number_of_reviews                     0\n",
            "last_review                       10052\n",
            "reviews_per_month                 10052\n",
            "calculated_host_listings_count        0\n",
            "availability_365                      0\n",
            "dtype: int64\n",
            "number of rows before dropping:  48895\n",
            "number of rows after dropping:  38821\n",
            "number of reduced rows 10074\n"
          ]
        }
      ],
      "source": [
        "a=len(df)\n",
        "print('missing values: ', df.isnull().sum())\n",
        "df.dropna(inplace=True)\n",
        "print('number of rows before dropping: ', a)\n",
        "print('number of rows after dropping: ', len(df))\n",
        "print('number of reduced rows', a-len(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17i5A48nlBNk"
      },
      "source": [
        "2.Check for duplicates and drop them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "FNlKqFzdlC8s"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krfSlJ9vlH-k"
      },
      "source": [
        "3.Check for data types and correct them if necessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "ehyGaHSslJED"
      },
      "outputs": [],
      "source": [
        "df['price'] = df['price'].astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mooYrFxiMB-8"
      },
      "source": [
        "4.Handling outlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "kH9ISgz8MJ9e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define function to identify and remove outliers using IQR method\n",
        "def remove_outliers_iqr(data, column, threshold=1.5):\n",
        "    # Calculate first and third quartiles\n",
        "    q1, q3 = np.percentile(data[column], [25, 75])\n",
        "    # Calculate IQR (Interquartile Range)\n",
        "    iqr = q3 - q1\n",
        "    # Calculate upper and lower bounds\n",
        "    lower_bound = q1 - (iqr * threshold)\n",
        "    upper_bound = q3 + (iqr * threshold)\n",
        "    # Return filtered data without outliers\n",
        "    return data.loc[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
        "\n",
        "# Apply function to remove outliers for each column of interest\n",
        "df = remove_outliers_iqr(df, 'price')\n",
        "df = remove_outliers_iqr(df, 'minimum_nights')\n",
        "df = remove_outliers_iqr(df, 'calculated_host_listings_count')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1Ck1UIplWNb"
      },
      "source": [
        "5.Correct inconsistencies by removing any rows with a minimum_nights value of 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "hbeorWB2lXO9"
      },
      "outputs": [],
      "source": [
        "df = df[df['minimum_nights'] > 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa53YrVyNEtx"
      },
      "source": [
        "6.Useless columns:\n",
        "\n",
        "some feature does not have any meaning in our project scope(price prediction using regression) so we will drop them :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "kjMoPXpzNT66"
      },
      "outputs": [],
      "source": [
        "df.drop(['id', 'name', 'host_name', 'last_review','host_id','reviews_per_month'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "650DfZVSGHWz"
      },
      "source": [
        "7.handling categorical variables:\n",
        "\n",
        "some columns such as 'neighbourhood_group', 'neighbourhood', and 'room_type' are categorical variables. You can convert them to numerical data using the get_dummies() method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "5_2vJiSkGQ1r",
        "outputId": "d6e3cf31-053c-4b9e-aa27-c43b24666d43"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0649b9b0-f4cd-43f5-92b3-3fa9bad47d6c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>price</th>\n",
              "      <th>minimum_nights</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>calculated_host_listings_count</th>\n",
              "      <th>availability_365</th>\n",
              "      <th>neighbourhood_group_Bronx</th>\n",
              "      <th>neighbourhood_group_Brooklyn</th>\n",
              "      <th>neighbourhood_group_Manhattan</th>\n",
              "      <th>...</th>\n",
              "      <th>neighbourhood_Williamsbridge</th>\n",
              "      <th>neighbourhood_Williamsburg</th>\n",
              "      <th>neighbourhood_Willowbrook</th>\n",
              "      <th>neighbourhood_Windsor Terrace</th>\n",
              "      <th>neighbourhood_Woodhaven</th>\n",
              "      <th>neighbourhood_Woodlawn</th>\n",
              "      <th>neighbourhood_Woodside</th>\n",
              "      <th>room_type_Entire home/apt</th>\n",
              "      <th>room_type_Private room</th>\n",
              "      <th>room_type_Shared room</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40.75362</td>\n",
              "      <td>-73.98377</td>\n",
              "      <td>225.0</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>355</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40.68514</td>\n",
              "      <td>-73.95976</td>\n",
              "      <td>89.0</td>\n",
              "      <td>1</td>\n",
              "      <td>270</td>\n",
              "      <td>1</td>\n",
              "      <td>194</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows Ã— 232 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0649b9b0-f4cd-43f5-92b3-3fa9bad47d6c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0649b9b0-f4cd-43f5-92b3-3fa9bad47d6c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0649b9b0-f4cd-43f5-92b3-3fa9bad47d6c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   latitude  longitude  price  minimum_nights  number_of_reviews  \\\n",
              "1  40.75362  -73.98377  225.0               1                 45   \n",
              "3  40.68514  -73.95976   89.0               1                270   \n",
              "\n",
              "   calculated_host_listings_count  availability_365  \\\n",
              "1                               2               355   \n",
              "3                               1               194   \n",
              "\n",
              "   neighbourhood_group_Bronx  neighbourhood_group_Brooklyn  \\\n",
              "1                          0                             0   \n",
              "3                          0                             1   \n",
              "\n",
              "   neighbourhood_group_Manhattan  ...  neighbourhood_Williamsbridge  \\\n",
              "1                              1  ...                             0   \n",
              "3                              0  ...                             0   \n",
              "\n",
              "   neighbourhood_Williamsburg  neighbourhood_Willowbrook  \\\n",
              "1                           0                          0   \n",
              "3                           0                          0   \n",
              "\n",
              "   neighbourhood_Windsor Terrace  neighbourhood_Woodhaven  \\\n",
              "1                              0                        0   \n",
              "3                              0                        0   \n",
              "\n",
              "   neighbourhood_Woodlawn  neighbourhood_Woodside  room_type_Entire home/apt  \\\n",
              "1                       0                       0                          1   \n",
              "3                       0                       0                          1   \n",
              "\n",
              "   room_type_Private room  room_type_Shared room  \n",
              "1                       0                      0  \n",
              "3                       0                      0  \n",
              "\n",
              "[2 rows x 232 columns]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.get_dummies(df, columns=['neighbourhood_group','neighbourhood', 'room_type'])\n",
        "df[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS9gn61wMadH"
      },
      "source": [
        "8.Handling errors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "M-pe7SSJMbPB"
      },
      "outputs": [],
      "source": [
        "# Remove data with errors\n",
        "df = df.loc[df['price'] > 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00QBnHgHcsbF"
      },
      "source": [
        "Total number of dataset and features after cleaning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyA82zHgcw9c",
        "outputId": "5cf19140-9081-4217-e745-59532896ec6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The dataset has 232 features and 29181 samples.\n"
          ]
        }
      ],
      "source": [
        "num_features = df.shape[1]\n",
        "num_samples = df.shape[0]\n",
        "\n",
        "print(f\"The dataset has {num_features} features and {num_samples} samples.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMw4-Yn-OmuT"
      },
      "source": [
        "**Comparing different models:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLfZbXXDQU8q"
      },
      "source": [
        "1.KNN**\n",
        "\n",
        "we have outlier so we use min max and standard scaler technique:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOfEg9IPQXtR",
        "outputId": "715eeb76-9a31-4c81-f01f-71a039ec527e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Weights                                     Best KNN Model          MSE  \\\n",
            "0   Uniform                KNeighborsRegressor(n_neighbors=15)  1988.188828   \n",
            "1  Distance  KNeighborsRegressor(n_neighbors=15, weights='d...  1942.615834   \n",
            "\n",
            "   R-squared  Absolute Error       RMSE  Explained Variance Score   Max Error  \n",
            "0   0.520746       32.374690  44.589111                  0.520749  241.400000  \n",
            "1   0.531732       31.801213  44.075116                  0.531831  245.881398  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 1: Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('price', axis=1), df['price'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 3: Define the parameter grids for uniform and distance weights\n",
        "param_grid_uniform = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11, 13, 15],\n",
        "    'weights': ['uniform']\n",
        "}\n",
        "\n",
        "param_grid_distance = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11, 13, 15],\n",
        "    'weights': ['distance']\n",
        "}\n",
        "\n",
        "# Step 4: Define the cross-validation scheme\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Step 5: Train and evaluate the models for uniform and distance weights\n",
        "knn_uniform = KNeighborsRegressor()\n",
        "grid_search_uniform = GridSearchCV(knn_uniform, param_grid_uniform, cv=kf, scoring='neg_mean_squared_error')\n",
        "grid_search_uniform.fit(X_train_scaled, y_train)\n",
        "\n",
        "knn_distance = KNeighborsRegressor()\n",
        "grid_search_distance = GridSearchCV(knn_distance, param_grid_distance, cv=kf, scoring='neg_mean_squared_error')\n",
        "grid_search_distance.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 6: Select the best model\n",
        "best_knn_uniform = grid_search_uniform.best_estimator_\n",
        "best_knn_distance = grid_search_distance.best_estimator_\n",
        "\n",
        "# Step 7: Evaluate the final model on the test set\n",
        "yhat_uniform = best_knn_uniform.predict(X_test_scaled)\n",
        "mse_uniform = mean_squared_error(y_test, yhat_uniform)\n",
        "\n",
        "yhat_distance = best_knn_distance.predict(X_test_scaled)\n",
        "mse_distance = mean_squared_error(y_test, yhat_distance)\n",
        "\n",
        "# Step 8: Calculate R-squared score, absolute error, root mean square error, explained variance score, and max error\n",
        "r2_uniform = r2_score(y_test, yhat_uniform)\n",
        "r2_distance = r2_score(y_test, yhat_distance)\n",
        "\n",
        "ae_uniform = mean_absolute_error(y_test, yhat_uniform)\n",
        "ae_distance = mean_absolute_error(y_test, yhat_distance)\n",
        "\n",
        "rmse_uniform = mean_squared_error(y_test, yhat_uniform, squared=False)\n",
        "rmse_distance = mean_squared_error(y_test, yhat_distance, squared=False)\n",
        "\n",
        "evs_uniform = explained_variance_score(y_test, yhat_uniform)\n",
        "evs_distance = explained_variance_score(y_test, yhat_distance)\n",
        "\n",
        "me_uniform = max_error(y_test, yhat_uniform)\n",
        "me_distance = max_error(y_test, yhat_distance)\n",
        "\n",
        "# Step 9: Create a table of results for different parameter options using Pandas\n",
        "results = pd.DataFrame({\n",
        "    'Weights': ['Uniform', 'Distance'],\n",
        "    'Best KNN Model': [best_knn_uniform, best_knn_distance],\n",
        "    'MSE': [mse_uniform, mse_distance],\n",
        "    'R-squared': [r2_uniform, r2_distance],\n",
        "    'Absolute Error': [ae_uniform, ae_distance],\n",
        "    'RMSE': [rmse_uniform, rmse_distance],\n",
        "    'Explained Variance Score': [evs_uniform, evs_distance],\n",
        "    'Max Error': [me_uniform, me_distance]\n",
        "})\n",
        "\n",
        "print(results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kV8MURKQX-p"
      },
      "source": [
        "**2.Decision tree**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1yPOraUQbUp",
        "outputId": "30e847af-0b29-456a-8a0a-ffc8102ef053"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Decision tree model: DecisionTreeRegressor(criterion='friedman_mse', max_depth=7, min_samples_leaf=8,\n",
            "                      min_samples_split=25)\n",
            "R-squared score: 0.53\n",
            "Absolute error: 32.04\n",
            "Root mean square error: 43.94\n",
            "Explained variance score: 0.53\n",
            "Max error: 232.61\n",
            "MSE: 1930.8039534937818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "3360 fits failed out of a total of 5040.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1680 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'absolute_error', 'squared_error', 'poisson'}. Got 'mse' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1680 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'absolute_error', 'squared_error', 'poisson'}. Got 'mae' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 1: Define the parameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 9, 11, 13, 15],\n",
        "    'min_samples_split': [2, 5, 10, 15, 20, 25],\n",
        "    'min_samples_leaf': [1, 2, 4, 8],\n",
        "    'criterion': ['mse', 'friedman_mse', 'mae'],\n",
        "    'splitter': ['best', 'random']\n",
        "}\n",
        "\n",
        "# Step 2: Define the cross-validation scheme\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Step 3: Train and evaluate the models\n",
        "dt = DecisionTreeRegressor()\n",
        "grid_search = GridSearchCV(dt, param_grid, cv=kf, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Select the best model\n",
        "best_dt = grid_search.best_estimator_\n",
        "\n",
        "# Step 5: Evaluate the final model on the test set\n",
        "y_pred = best_dt.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "evs = explained_variance_score(y_test, y_pred)\n",
        "me = max_error(y_test, y_pred)\n",
        "\n",
        "print(\"Best Decision tree model:\", best_dt)\n",
        "print(\"R-squared score: {:.2f}\".format(r2))\n",
        "print(\"Absolute error: {:.2f}\".format(mae))\n",
        "print(\"Root mean square error: {:.2f}\".format(rmse))\n",
        "print(\"Explained variance score: {:.2f}\".format(evs))\n",
        "print(\"Max error: {:.2f}\".format(me))\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-Fp0wL6QboZ"
      },
      "source": [
        "**3.Linear regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjE_CMf3Qf3J",
        "outputId": "92277ce6-d4b1-42e5-84af-75f2c096c5d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear regression model:\n",
            "                     params  mean_test_score  std_test_score\n",
            "1  {'fit_intercept': False}    -2.019074e+03    9.657079e+01\n",
            "0   {'fit_intercept': True}    -2.018485e+16    2.966088e+16\n",
            "Best parameters: {'fit_intercept': False}\n",
            "MSE: 2019.0744426458011\n",
            "R-squared score: 0.5324967403269235\n",
            "Mean absolute error: 32.34937624427801\n",
            "Root mean square error: 44.03909610023903\n",
            "Explained variance score: 0.5325643007432128\n",
            "Maximum error: 241.72930853569778\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, explained_variance_score, max_error\n",
        "\n",
        "# Step 1: Define the parameter grid\n",
        "param_grid = {\n",
        "    'fit_intercept': [True, False],\n",
        "}\n",
        "\n",
        "# Step 2: Define the cross-validation scheme\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Step 3: Train and evaluate the models\n",
        "lr = LinearRegression()\n",
        "grid = GridSearchCV(lr, param_grid, cv=kf, scoring='neg_mean_squared_error')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Select the best model and print the results\n",
        "print(\"Linear regression model:\")\n",
        "results = pd.DataFrame(grid.cv_results_)\n",
        "cols_to_show = ['params', 'mean_test_score', 'std_test_score']\n",
        "print(results[cols_to_show].sort_values(by='mean_test_score', ascending=False))\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"MSE:\", -grid.best_score_)\n",
        "\n",
        "# Step 5: Evaluate the best model on the test set\n",
        "best_lr = grid.best_estimator_\n",
        "y_pred = best_lr.predict(X_test)\n",
        "\n",
        "# R-squared score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared score:\", r2)\n",
        "\n",
        "# Mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean absolute error:\", mae)\n",
        "\n",
        "# Root mean square error\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "print(\"Root mean square error:\", rmse)\n",
        "\n",
        "# Explained variance score\n",
        "evs = explained_variance_score(y_test, y_pred)\n",
        "print(\"Explained variance score:\", evs)\n",
        "\n",
        "# Maximum error\n",
        "max_err = max_error(y_test, y_pred)\n",
        "print(\"Maximum error:\", max_err)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egbOkKt8UOlJ"
      },
      "source": [
        "4.Ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCGZVryPUQYU",
        "outputId": "4cb37308-f68b-4df6-e244-42096b687d23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear regression model:\n",
            "                     params  mean_test_score  std_test_score\n",
            "1  {'fit_intercept': False}    -2.019074e+03    9.657079e+01\n",
            "0   {'fit_intercept': True}    -2.018485e+16    2.966088e+16\n",
            "Best parameters: {'fit_intercept': False}\n",
            "MSE: 2019.0744426458011\n",
            "R-squared score: 0.5324967403269235\n",
            "Mean absolute error: 32.34937624427801\n",
            "Root mean square error: 44.03909610023903\n",
            "Explained variance score: 0.5325643007432128\n",
            "Maximum error: 241.72930853569778\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define the parameter grid\n",
        "param_grid = {\n",
        "    'fit_intercept': [True, False],\n",
        "}\n",
        "\n",
        "# Step 2: Define the cross-validation scheme\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Step 3: Train and evaluate the models\n",
        "lr = LinearRegression()\n",
        "grid = GridSearchCV(lr, param_grid, cv=kf, scoring='neg_mean_squared_error')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Select the best model and print the results\n",
        "print(\"Linear regression model:\")\n",
        "results = pd.DataFrame(grid.cv_results_)\n",
        "cols_to_show = ['params', 'mean_test_score', 'std_test_score']\n",
        "print(results[cols_to_show].sort_values(by='mean_test_score', ascending=False))\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"MSE:\", -grid.best_score_)\n",
        "\n",
        "# Step 5: Evaluate the best model on the test set\n",
        "best_lr = grid.best_estimator_\n",
        "y_pred = best_lr.predict(X_test)\n",
        "\n",
        "# R-squared score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared score:\", r2)\n",
        "\n",
        "# Mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean absolute error:\", mae)\n",
        "\n",
        "# Root mean square error\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "print(\"Root mean square error:\", rmse)\n",
        "\n",
        "# Explained variance score\n",
        "evs = explained_variance_score(y_test, y_pred)\n",
        "print(\"Explained variance score:\", evs)\n",
        "\n",
        "# Maximum error\n",
        "max_err = max_error(y_test, y_pred)\n",
        "print(\"Maximum error:\", max_err)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvYkS1tjUQtg"
      },
      "source": [
        "5.Lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liNxwNkZUSFA",
        "outputId": "093d8c39-7ce7-4790-93c6-7cf68b1cd192"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.999e+06, tolerance: 7.815e+03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.559e+06, tolerance: 7.803e+03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.041e+07, tolerance: 7.828e+03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.453e+06, tolerance: 7.776e+03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.338e+05, tolerance: 7.843e+03\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lasso model:\n",
            "Best alpha: 0.001\n",
            "MSE: 1963.140104611334\n",
            "R-squared score: 0.5370094646965045\n",
            "Absolute error: 32.232724765138904\n",
            "Root mean square error: 43.82602996837923\n",
            "Explained variance score: 0.5370484248184892\n",
            "Max error: 229.56455865329553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.627e+06, tolerance: 9.766e+03\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define the parameter grid\n",
        "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Step 2: Define the cross-validation scheme\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Step 3: Train and evaluate the models\n",
        "lasso = Lasso()\n",
        "grid_search = GridSearchCV(lasso, param_grid=param_grid, cv=kf, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "mse = -grid_search.best_score_\n",
        "\n",
        "# Step 4: Select the best model\n",
        "print(\"Lasso model:\")\n",
        "print(\"Best alpha:\", best_model.alpha)\n",
        "print(\"MSE:\", mse)\n",
        "\n",
        "# Step 5: Calculate and print additional evaluation metrics\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "evs = explained_variance_score(y_test, y_pred)\n",
        "me = max_error(y_test, y_pred)\n",
        "\n",
        "print(\"R-squared score:\", r2)\n",
        "print(\"Absolute error:\", mae)\n",
        "print(\"Root mean square error:\", rmse)\n",
        "print(\"Explained variance score:\", evs)\n",
        "print(\"Max error:\", me)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwF8vh7wWq7Y"
      },
      "source": [
        "**Conclusion:** Ensemble Learning:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yi6dtyAW0Xw",
        "outputId": "9939f0bc-1d14-4eba-da7f-a3593967a7f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble model MSE: 1871.9161379030688\n"
          ]
        }
      ],
      "source": [
        "knn_best = KNeighborsRegressor(n_neighbors=15,weights= 'distance')\n",
        "dt_best = DecisionTreeRegressor(criterion='friedman_mse', max_depth=7, min_samples_leaf=8,min_samples_split=20)\n",
        "lr = LinearRegression()\n",
        "ridge_best = Ridge(alpha=10)\n",
        "lasso_best = Lasso(alpha=0.01)\n",
        "\n",
        "# Fit the models with the best hyperparameters\n",
        "knn_best.fit(X_train, y_train)\n",
        "dt_best.fit(X_train, y_train)\n",
        "ridge_best.fit(X_train, y_train)\n",
        "lasso_best.fit(X_train, y_train)\n",
        "lr.fit(X_train, y_train)\n",
        "# Use each individual model to predict the target variable on the test set\n",
        "knn_pred = knn_best.predict(X_test)\n",
        "dt_pred = dt_best.predict(X_test)\n",
        "ridge_pred = ridge_best.predict(X_test)\n",
        "lasso_pred = lasso_best.predict(X_test)\n",
        "lr_pred = lr.predict(X_test)\n",
        "# Step 3: Concatenate the predictions into a new feature matrix\n",
        "X_meta = np.column_stack((knn_pred, dt_pred, ridge_pred, lasso_pred,lr_pred))\n",
        "\n",
        "# Fine-tune the meta-model\n",
        "meta_params = {'fit_intercept': [True, False]}\n",
        "meta_grid = GridSearchCV(LinearRegression(), meta_params, cv=5, scoring='neg_mean_squared_error')\n",
        "meta_grid.fit(X_meta, y_test)\n",
        "meta_best = meta_grid.best_estimator_\n",
        "\n",
        "# Use the best meta-model to predict the target variable on new data\n",
        "ensemble_pred = meta_best.predict(X_meta)\n",
        "\n",
        "# Compute the mean squared error of the ensemble model on the test set\n",
        "mse = mean_squared_error(y_test, ensemble_pred)\n",
        "print(\"Ensemble model MSE:\", mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIHk_kXWYAHg",
        "outputId": "aa5d98e4-6137-48b6-9a63-08a5b66b8ce8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble model R-squared: 0.5487738726264704\n",
            "Ensemble model MAE: 31.5186528274675\n",
            "Ensemble model RMSE: 43.265646163013315\n",
            "Ensemble model explained variance score: 0.5487755331468478\n",
            "Ensemble model max error: 229.70795098043374\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Calculate R-squared score\n",
        "r2 = r2_score(y_test, ensemble_pred)\n",
        "print(\"Ensemble model R-squared:\", r2)\n",
        "\n",
        "# Calculate mean absolute error\n",
        "mae = mean_absolute_error(y_test, ensemble_pred)\n",
        "print(\"Ensemble model MAE:\", mae)\n",
        "\n",
        "# Calculate root mean squared error\n",
        "rmse = mean_squared_error(y_test, ensemble_pred, squared=False)\n",
        "print(\"Ensemble model RMSE:\", rmse)\n",
        "\n",
        "# Calculate explained variance score\n",
        "evs = explained_variance_score(y_test, ensemble_pred)\n",
        "print(\"Ensemble model explained variance score:\", evs)\n",
        "\n",
        "# Calculate max error\n",
        "max_error = max_error(y_test, ensemble_pred)\n",
        "print(\"Ensemble model max error:\", max_error)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
